{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在尝试从以下路径导入模块: .dinov2_backbone\n",
      "正在查找类: Dinov2Backbone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cartolab3/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/cartolab3/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/cartolab3/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AggMInterface(\n",
       "  (model): Dinov2Backbone(\n",
       "    (reduce_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (model): DinoVisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-23): 24 x NestedTensorBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MemEffAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (head): Identity()\n",
       "    )\n",
       "  )\n",
       "  (metric_loss_function): MetricLoss(\n",
       "    (loss_fn): MultiSimilarityLoss(\n",
       "      (distance): CosineSimilarity()\n",
       "      (reducer): MeanReducer()\n",
       "    )\n",
       "    (miner): MultiSimilarityMiner(\n",
       "      (distance): CosineSimilarity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from model import AggMInterface\n",
    "from data import DInterface\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 指定checkpoint和模型超参数\n",
    "config_path = \"/media/cartolab3/DataDisk/wuqilong_file/Projects/RerenkVPR/logs/dinov2_backbone_dinov2_large/lightning_logs/version_0/hparams.yaml\"\n",
    "checkpoint_path = \"/media/cartolab3/DataDisk/wuqilong_file/Projects/RerenkVPR/logs/dinov2_backbone_dinov2_large/lightning_logs/version_0/checkpoints/dinov2_backbone_epoch(14)_step(14655)_R1[0.9149]_R5[0.9622]_R10[0.9703].ckpt\"\n",
    "\n",
    "# 加载yaml文件\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 初始化data moudle\n",
    "data_module = DInterface(**config)  # 数据相关配置\n",
    "transform = data_module.valid_transform  # val transform\n",
    "\n",
    "# 初始化model\n",
    "model = AggMInterface.load_from_checkpoint(checkpoint_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import cv2\n",
    "from einops import rearrange\n",
    "from visualization.visualization_tools import get_pca_map\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# input_image_path\n",
    "input_image_path = \"/media/cartolab3/DataDisk/wuqilong_file/Projects/RerenkVPR/imgs/output_imgs/nordland/0000003.jpg\"\n",
    "image_size = (560,560)\n",
    "\n",
    "def visualize_dinov2(input_image_path, image_size=(322,322)):\n",
    "    # 定义加载图像并resize，输出tensor的transform\n",
    "    ori_image = Image.open(input_image_path)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image=transform(ori_image).unsqueeze(0).cuda()\n",
    "    print(image.shape)\n",
    "\n",
    "    # 输入模型\n",
    "    cls_token, patch_tokens, (q, k, v) = model.forward(image,is_training=False,block_idx=-1)\n",
    "    print(patch_tokens.shape)\n",
    "\n",
    "    # 获取特征图\n",
    "    features = patch_tokens.detach().cpu()\n",
    "    features = rearrange(features, 'b (h w) c -> b h w c', h= int(image_size[0]/14), w=int(image_size[1]/14))\n",
    "    features = features[0].float()\n",
    "\n",
    "    # 设置重采样图大小\n",
    "    color = get_pca_map(features, image_size, interpolation='bilinear')\n",
    "    color=(color*255).astype(np.uint8)\n",
    "    print(color.shape)\n",
    "\n",
    "    # 将color代表的图像和原始图像拼接，形成一行两列的图像\n",
    "    image = np.hstack((ori_image.resize(image_size), color))\n",
    "    print(image.shape)\n",
    "\n",
    "    # 定义输出文件名称\n",
    "    output_file = f'{os.path.dirname(input_image_path)}/{os.path.basename(input_image_path).split(\".\")[0]}_dinov2_finetune.jpg'\n",
    "\n",
    "    # cv2.imwrite(output_file, image)\n",
    "    rgb_image = Image.fromarray(image)\n",
    "    rgb_image.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([1, 3, 560, 560])\n",
      "torch.Size([1, 1600, 1024])\n",
      "(560, 560, 3)\n",
      "(560, 1120, 3)\n",
      "torch.Size([1, 3, 560, 560])\n",
      "torch.Size([1, 1600, 1024])\n",
      "(560, 560, 3)\n",
      "(560, 1120, 3)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# 可视化多张图像\n",
    "img_path=\"./imgs/output_imgs/tokyo\"\n",
    "image_list = glob.glob(os.path.join(img_path, \"*.jpg\"))\n",
    "print(len(image_list))\n",
    "for image_path in image_list:\n",
    "    if 'dinov2' not in image_path:\n",
    "        visualize_dinov2(image_path,image_size=image_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wuqilong_lighting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
