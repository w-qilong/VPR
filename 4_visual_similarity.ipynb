{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/cartolab3/DataDisk/wuqilong_file/Projects/RerenkVPR/utils/hook_func.py:21: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在尝试从以下路径导入模块: .dinov2_backbone\n",
      "正在查找类: Dinov2Backbone\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DinoVisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-23): 24 x NestedTensorBlock(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MemEffAttention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from model import AggMInterface\n",
    "from data import DInterface\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 指定模型的超参数配置文件路径和checkpoint文件路径\n",
    "config_path = \"logs/dinov2_backbone_dinov2_large/lightning_logs/version_8/hparams.yaml\"\n",
    "checkpoint_path = \"logs/dinov2_backbone_dinov2_large/lightning_logs/version_8/checkpoints/dinov2_backbone_epoch(11)_step(11724)_R1[0.9014]_R5[0.9622]_R10[0.9703].ckpt\"\n",
    "\n",
    "# 加载yaml文件，获取模型超参数配置\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 根据配置初始化数据模块\n",
    "data_module = DInterface(**config)  # 数据模块初始化，传入配置参数\n",
    "transform = data_module.valid_transform  # 获取验证集的数据变换方法\n",
    "\n",
    "# 根据checkpoint文件路径加载模型，并设置为评估模式\n",
    "model = AggMInterface.load_from_checkpoint(checkpoint_path)\n",
    "model.eval()\n",
    "model = model.model.model\n",
    "model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacty of 23.54 GiB of which 1.05 GiB is free. Process 2840935 has 422.64 MiB memory in use. Process 1787300 has 3.10 GiB memory in use. Process 2970667 has 13.21 GiB memory in use. Including non-PyTorch memory, this process has 5.29 GiB memory in use. Of the allocated memory 4.79 GiB is allocated by PyTorch, and 38.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 计算视觉相似度\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m similarity_maps, source_img, target_img \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_visual_similarity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_image_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_image_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 计算注意力图最大值位置\u001b[39;00m\n\u001b[1;32m     30\u001b[0m key_max \u001b[38;5;241m=\u001b[39m mode(np\u001b[38;5;241m.\u001b[39margwhere(similarity_maps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m similarity_maps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mmode[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/media/cartolab3/DataDisk/wuqilong_file/Projects/RerenkVPR/utils/hook_func.py:892\u001b[0m, in \u001b[0;36mcompute_visual_similarity\u001b[0;34m(source_path, target_path, model, query_point, layer_idx, image_size, device)\u001b[0m\n\u001b[1;32m    886\u001b[0m     source_feat, target_feat \u001b[38;5;241m=\u001b[39m _extract_features(\n\u001b[1;32m    887\u001b[0m         model, source_img, target_img, feature_type, \n\u001b[1;32m    888\u001b[0m         layer_idx, hook_outputs\n\u001b[1;32m    889\u001b[0m     )\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# 计算相似度图\u001b[39;00m\n\u001b[0;32m--> 892\u001b[0m     similarity_map \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_similarity_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_feat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_point\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m     similarity_maps[feature_type] \u001b[38;5;241m=\u001b[39m similarity_map\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity_maps, source_pil\u001b[38;5;241m.\u001b[39mresize((image_size, image_size)), target_pil\u001b[38;5;241m.\u001b[39mresize((image_size, image_size))\n",
      "File \u001b[0;32m/media/cartolab3/DataDisk/wuqilong_file/Projects/RerenkVPR/utils/hook_func.py:1029\u001b[0m, in \u001b[0;36m_compute_similarity_map\u001b[0;34m(source_feat, target_feat, query_point, num_patches, image_size)\u001b[0m\n\u001b[1;32m   1021\u001b[0m query_feat \u001b[38;5;241m=\u001b[39m source_feat[[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, query_point[\u001b[38;5;241m1\u001b[39m], query_point[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m   1022\u001b[0m query_feat \u001b[38;5;241m=\u001b[39m ein\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[1;32m   1023\u001b[0m     query_feat,\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 d -> 1 d h w\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1025\u001b[0m     h\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[1;32m   1026\u001b[0m     w\u001b[38;5;241m=\u001b[39mimage_size\n\u001b[1;32m   1027\u001b[0m )\n\u001b[0;32m-> 1029\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ein\u001b[38;5;241m.\u001b[39mrearrange(\n\u001b[1;32m   1031\u001b[0m     similarity,\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 h w -> h w 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacty of 23.54 GiB of which 1.05 GiB is free. Process 2840935 has 422.64 MiB memory in use. Process 1787300 has 3.10 GiB memory in use. Process 2970667 has 13.21 GiB memory in use. Including non-PyTorch memory, this process has 5.29 GiB memory in use. Of the allocated memory 4.79 GiB is allocated by PyTorch, and 38.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from utils.hook_func import compute_visual_similarity, create_attention_similarity_plot\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "source_image_path = \"tmp_imgs/00010.jpg\"\n",
    "target_image_path = \"tmp_imgs/00012.jpg\"\n",
    "\n",
    "source_image_path = \"sample_imgs/msls/3/query/oYwU28V-MzaKyX9R18zlMQ.jpg\"\n",
    "target_image_path = \"sample_imgs/msls/3/ref/aEfMlCMFxwR_QY-e5KvTDw.jpg\"\n",
    "\n",
    "image_size = 560\n",
    "query_point = (181, 272)\n",
    "layer_idx = 17\n",
    "device = \"cuda\"\n",
    "\n",
    "# 计算视觉相似度\n",
    "similarity_maps, source_img, target_img = compute_visual_similarity(\n",
    "    source_image_path,\n",
    "    target_image_path,\n",
    "    model,\n",
    "    query_point,\n",
    "    layer_idx,\n",
    "    image_size,\n",
    "    device\n",
    ")\n",
    "\n",
    "# 计算注意力图最大值位置\n",
    "key_max = mode(np.argwhere(similarity_maps[\"key\"].max() == similarity_maps[\"key\"]), axis=0).mode[:2]\n",
    "query_max = mode(np.argwhere(similarity_maps[\"query\"].max()==similarity_maps[\"query\"]), axis=0).mode[:2]  \n",
    "value_max = mode(np.argwhere(similarity_maps[\"value\"].max()==similarity_maps[\"value\"]), axis=0).mode[:2]\n",
    "token_max = mode(np.argwhere(similarity_maps[\"token\"].max()==similarity_maps[\"token\"]), axis=0).mode[:2]\n",
    "\n",
    "# 将最大值位置存储在字典中\n",
    "max_positions = {\n",
    "    \"key\": key_max,\n",
    "    \"query\": query_max,\n",
    "    \"value\": value_max,\n",
    "    \"token\": token_max\n",
    "}\n",
    "\n",
    "# 可视化注意力相似度\n",
    "fig = create_attention_similarity_plot(\n",
    "    source_image=source_img,\n",
    "    target_image=target_img,\n",
    "    attention_maps=similarity_maps,\n",
    "    source_point=query_point,\n",
    "    max_positions=max_positions,\n",
    "    fig_size=(36, 8),\n",
    "    dpi=500\n",
    ")\n",
    "\n",
    "# 可以选择保存图形\n",
    "# 设置保存路径\n",
    "save=False\n",
    "if save:\n",
    "    save_folder = r\"tmp_imgs\"\n",
    "    if not os.path.isdir(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "        print(f\"Directory created: {save_folder}\")\n",
    "    else:\n",
    "        print(f\"Destination directory '{save_folder}' already exists!\")\n",
    "    save_fname = f\"I{source_image_path.split('/')[-1]}-{target_image_path.split('/')[-1]}_Px{query_point[0]}_Py{query_point[1]}.png\"\n",
    "    if save_folder:\n",
    "        fig.savefig(os.path.join(save_folder, save_fname), bbox_inches='tight')\n",
    "\n",
    "# 可以选择显示图形\n",
    "plt.show(fig)\n",
    "\n",
    "# 清理图形以释放内存\n",
    "plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wuqilong_lighting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
